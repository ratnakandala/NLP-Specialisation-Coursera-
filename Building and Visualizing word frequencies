import nltk                             #Python library
from nltk.corpus import twitter_samples #sample Twitter dataset from NLTK
import matplotlib.pyplot as plt         # visualization library
import nympy as np                      #Library for scientific computing and matrix operations

nltk.download('twitter_samples')

#Helper functions in the utils.py file
# process_tweet() : cleans the text, tokenizes it into separate words, removes stopwords, and converts words to stems
# build_freqs() : counts how often a word in the 'corpus' (the entire set of tweets) was associated with a positive label 1 or a negative label 0.
# It then builds the 'freqs' dictionary, where each key is a (word, label) tuple, and the value is the count of its frequency within the corpus of tweets.

nltk.download('stopwords')                     #download the stopwords for the process_tweet function
from utils import process_tweet, build_freqs   #import our convenience functions

LOAD THE NLTK SAMPLE (TWITTER) DATASET

all_positive_tweets = twitter_samples.strings('positive_tweets.json')  #selecting all postiive tweets
all_negative_tweets = twitter_samples.strings('negative_tweets.json')  #selecting all negative tweets


